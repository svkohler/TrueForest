# Data storage
data_store: "to-be-set"
dump_path: "to-be-set" # path were intermediate files are dumped

# Set seed for reproducability
seed_run: 1
seed: 36573 # [seed 1: 36573, seed 2: 90708, seed 3: 23012]

# run mode
run_mode: "train_encoder" # choices: all, train, train_encoder, train_classifier, test

# data information
patch_size: 224
location: "Central_Valley"

# model specifications
model_name: "SwAV"
base_architecture: "resnet50" # choices: resnet50, resnet101, wide_resnet50_2, wide_resnet101_2
num_features: 128 # size of feature vector which is used for loss function
num_hidden: 2048 # size of hidden layer in projection head
num_projection: 128 # size after projection

# training parameter
num_epochs: 100
batch_size: 256
shuffle: True
num_workers: 16
pin_memory: True
fp16_precision: True

# model specific training parameters
temperature: 0.1 # --used
normalize: True
epsilon: 0.03 # --used
queue_length: 3840
epoch_queue_starts: 15
sinkhorn_iterations: 3
freeze_prototypes_niters: 5005
num_prototypes: 3000

# learning rate schedule
init_lr: 0.6 # --used
final_lr: 0.0006 # --used
momentum: 0.9
weight_decay: 0.000001 # --used
warm_up_epochs: 0 # --used
init_warm_up_lr: 0
ema_factor: 0.99

# log
print_freq: 100

# whether to transform images
transforms:
  implement: True
  hflip: True
  hflip_prob: 0.5
  vflip: True
  vflip_prob: 0.5
  rotate: True
  contrast: True
  contrast_prob: 0.3
  hue: True
  hue_prob: 0.1
  gamma: True
  gamma_prob: 0.3
  saturation: True
  saturation_prob: 0.3
  gaussian_blur: True
  gaussian_blur_prob: 0.2
  normalize: False

# --------------------------

# binary classifier
classify: True
clf: "xgboost" # choices random_forest, linear, xgboost, MLP
neg_samples_factor: 1 # positive int

# ------------------------

best_epoch: None
